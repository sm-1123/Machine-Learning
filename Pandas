-------------------------date:02/07/2024-------------------------------------
..
import pandas as pd

data = {
    'Name':['Rahul', 'Rohit', 'Virat'],
    'Age':[25, 30, 18],
    'City':['Vizag', 'Mumbai', 'Delhi']
}

df = pd.DataFrame(data)

print("Original DataFrame:")

print(df)

df['Playing Style'] = ['Classic', 'Hitman', 'Perfectioist']

print("\n DataFrame with a new column:")

print(df)

Original DataFrame:
    Name  Age    City
0  Rahul   25   Vizag
1  Rohit   30  Mumbai
2  Virat   18   Delhi

 DataFrame with a new column:
    Name  Age    City Playing Style
0  Rahul   25   Vizag       Classic
1  Rohit   30  Mumbai        Hitman
2  Virat   18   Delhi  Perfectioist
Features of Pandas

How to create a Series in Pandas

ser
import pandas as pd
​
import numpy as np
​
ser = pd.Series()
​
print(ser)
​
data = np.array(['n', 'i', 'n', 'j', 'a', 's'])
​
ser = pd.Series(data)
​
print(ser)
Series([], dtype: float64)
0    n
1    i
2    n
3    j
4    a
5    s
dtype: object
C:\Users\Sourav Mukherjee\AppData\Local\Temp\ipykernel_25544\3724197521.py:5: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.
  ser = pd.Series()
How to create a Dataframe in Pandas

df
import pandas as pd
​
df = pd.DataFrame()
​
print(df)
​
I = ['n', 'i', 'n', 'j', 'a', 's']
​
df = pd.DataFrame(I, columns = ['Letters'])
​
print(df)
Empty DataFrame
Columns: []
Index: []
  Letters
0       n
1       i
2       n
3       j
4       a
5       s
Reading CSV file

import pandas as pd
​
data = pd.read_csv('filename.csv')
​
print(data.head())
         date column_name  column_name1  column_name2
0  2022-01-01           A            10             5
1  2022-01-01           A            20             6
2  2022-01-01           B            15             7
3  2022-01-02           A            12             4
4  2022-01-02           B            18             6
Selecting Rows and Columns

import pandas as pd
​
data = pd.read_csv('filename.csv')
​
subset = data.loc[(data['column_name'] == 'A'), ['column_name1', 'column_name2']]
​
print(subset.head())
   column_name1  column_name2
0            10             5
1            20             6
3            12             4
6             9             3
Grouping and Aggregating Data

import pandas as pd
​
data = pd.read_csv('filename.csv')
​
grouped_data= data.groupby('column_name').agg({'column_name1':'sum', 'column_name2':'mean'})
​
print(grouped_data.head())
             column_name1  column_name2
column_name                            
A                      51           4.5
B                      82           6.4


##Difference Between NumPy and Pandas

Example of NumPy

import numpy as np
​
myArr = np.random.rand(2, 3)
​
print("Array is:", myArr)
​
print("Shape of the array is:", myArr.shape)
​
print("Number of dimensions:", myArr.ndim)
​
print("Sum of all elements is:", myArr.size)
​
print("Minimum value is:", myArr.min(), "and maximum value is:", myArr.max())
Array is: [[0.46500842 0.5716122  0.65411433]
 [0.87631066 0.41650137 0.8444056 ]]
Shape of the array is: (2, 3)
Number of dimensions: 2
Sum of all elements is: 6
Minimum value is: 0.4165013728456892 and maximum value is: 0.8763106577031533
Pandas in Python

Example of Pandas

subset
import pandas as pd
​
ninjasData = {'name':['Ninja1','Ninja2','Ninja3','Ninja4','Ninja5'],'age':[20,30,18,42,22],'city':['Mathura','Vrindavan','Lucknow','Delhi','Patna']}
​
dataFrame = pd.DataFrame(ninjasData)
​
print(dataFrame)
​
print()
​
mean_age = dataFrame['age'].mean()
​
print("Mean age is:", mean_age)
​
subset = dataFrame[dataFrame['age'] > 25]
​
print("Subset of dataFrame is:")
​
print(subset)
     name  age       city
0  Ninja1   20    Mathura
1  Ninja2   30  Vrindavan
2  Ninja3   18    Lucknow
3  Ninja4   42      Delhi
4  Ninja5   22      Patna

Mean age is: 26.4
Subset of dataFrame is:
     name  age       city
1  Ninja2   30  Vrindavan
3  Ninja4   42      Delhi

--------------------------------date:03/07/2024------------------------------------

Labels in Pandas Series

Creating Labels

Manual Label Assignment

import pandas as pd
​
data = [12,17,22,75]
​
labels = ['Aditya','Pradeep','Tanish','Bhavesh']
​
series = pd.Series(data,index=labels)
​
print(series)
Aditya     12
Pradeep    17
Tanish     22
Bhavesh    75
dtype: int64
Using Default Numeric Index

import pandas as pd
​
data = [12,17,22,75]
​
series = pd.Series(data)
​
print(series)
0    12
1    17
2    22
3    75
dtype: int64
Date-based Labels

e
import pandas as pd
​
import datetime
​
data = [12,17,22,75]
​
dates = [datetime.date(2024,9,1),datetime.date(2024,9,2),datetime.date(2024,9,3),datetime.date(2024,9,4)]
​
series = pd.Series(data,index=dates)
​
print(series)
2024-09-01    12
2024-09-02    17
2024-09-03    22
2024-09-04    75
dtype: int64
Using Python Range

import pandas as pd
​
data = [12,17,22,75]
​
labels = list(range(1, 5))
​
series = pd.Series(data, index=labels)
​
print(series)
1    12
2    17
3    22
4    75
dtype: int64
Converting a Dictionary to a Series

import pandas as pd
​
data_dict = {'Aditya':12,'Pradeep':17,'Tanish':22,'Bhavesh':75}
​
series = pd.Series(data_dict)
​
print(series)
Aditya     12
Pradeep    17
Tanish     22
Bhavesh    75
dtype: int64
Accessing Labels Using Label

Using Square Brackets ([ ])

import pandas as pd
​
data_dict = {'Aditya':12,'Pradeep':17,'Tanish':22,'Bhavesh':75}
​
series = pd.Series(data_dict)
​
value_at_Aditya = series['Aditya']
​
print(value_at_Aditya)
12
Using .loc[ ] Indexer

import pandas as pd
​
data_dict = {'Aditya':12,'Pradeep':17,'Tanish':22,'Bhavesh':75}
​
series = pd.Series(data_dict)
​
value_at_Pradeep = series.loc['Pradeep']
​
print(value_at_Pradeep)
17
Label-based Slicing

subset
import pandas as pd
​
data_dict = {'Aditya':12,'Pradeep':17,'Tanish':22,'Bhavesh':75}
​
series = pd.Series(data_dict)
​
subset = series['Pradeep':'Bhavesh']
​
print(subset)
Pradeep    17
Tanish     22
Bhavesh    75
dtype: int64
Conditional Selection with Labels

import pandas as pd
​
data_dict = {'Aditya':12,'Pradeep':17,'Tanish':22,'Bhavesh':75}
​
series = pd.Series(data_dict)
​
result = series[series > 25]
​
print(result)
Bhavesh    75
dtype: int64
Key/Value Objects as Series

import pandas as pd
​
data_dict = {'Aditya':12,'Pradeep':17,'Tanish':22,'Bhavesh':75}
​
series = pd.Series(data_dict)
​
print(series)
Aditya     12
Pradeep    17
Tanish     22
Bhavesh    75
dtype: int64


###Python DataFrame

Empty DataFrame

import pandas as pd
​
df = pd.DataFrame
​
print(df)
<class 'pandas.core.frame.DataFrame'>
DataFrame Using List

i
import pandas as pd
​
list = ['hii','my','name','is','sourav','mukherjee']
​
df = pd.DataFrame(list)
​
print(df)
           0
0        hii
1         my
2       name
3         is
4     sourav
5  mukherjee
Example 2

df
import pandas as pd
​
data = [['Robert',30],['Sam',25],['Diana',20],['Mark',33]]
​
labels = ['Name', 'Age']
​
df = pd.DataFrame(data, columns=labels)
​
print(df)
     Name  Age
0  Robert   30
1     Sam   25
2   Diana   20
3    Mark   33
Example 3

df
import pandas as pd
​
Data = [['Robert',30],['Sam',25],['Diana',20],['Mark',33]]
​
Labels = ['Name','Score']
​
df = pd.DataFrame(Data, columns=Labels, dtype=float)
​
print(df)
     Name  Score
0  Robert   30.0
1     Sam   25.0
2   Diana   20.0
3    Mark   33.0
C:\Users\Sourav Mukherjee\AppData\Local\Temp\ipykernel_18716\495983250.py:7: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.
  df = pd.DataFrame(Data, columns=Labels, dtype=float)
DataFrame from List of Dict

Example 1

df
import pandas as pd
​
data = [{'X':1,'Y':2,'Z':3},{'X':4,'Y':5,'Z':6}]
​
df = pd.DataFrame(data)
​
print(df)
   X  Y  Z
0  1  2  3
1  4  5  6
Example 2

df
import pandas as pd
​
data = [{'X':1,'Y':2,'Z':3},{'X':4,'Y':5}]
​
df = pd.DataFrame(data)
​
print(df)
   X  Y    Z
0  1  2  3.0
1  4  5  NaN
.
import pandas as pd
​
data = [{'X':1,'Y':2,'Z':3},{'X':4,'Y':5,'Z':6}]
​
row_idx = ['row1','row2']
​
col = ['X','Y','Z']
​
df = pd.DataFrame(data, index=row_idx, columns = col)
​
print(df)
      X  Y  Z
row1  1  2  3
row2  4  5  6
Example 3

df
import pandas as pd
​
data = [{'X':1,'Y':2,'Z':3},{'X':4,'Y':5,'Z':6}]
​
row_idx = ['row1','row2']
​
col = ['X','Z']
​
df = pd.DataFrame(data, index = row_idx, columns = col)
​
print(df)
      X  Z
row1  1  3
row2  4  6
DataFrame from Dict of Lists

Example

,
import pandas as pd
​
list1 = ['Robert','Sam','Diana','Mark']
​
list2 = [30,25,20,33]
​
data = {'Name':list1,'Score':list2}
​
df = pd.DataFrame(data)
​
print(df)
     Name  Score
0  Robert     30
1     Sam     25
2   Diana     20
3    Mark     33
data
import pandas as pd
​
list1 =['Robert','Sam','Diana','Mark']
​
list2 = [30, 25]
​
data = {'Name':list1,'Score':list2}
​
df = pd.DataFrame(data)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[24], line 9
      5 list2 = [30, 25]
      7 data = {'Name':list1,'Score':list2}
----> 9 df = pd.DataFrame(data)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\frame.py:664, in DataFrame.__init__(self, data, index, columns, dtype, copy)
    658     mgr = self._init_mgr(
    659         data, axes={"index": index, "columns": columns}, dtype=dtype, copy=copy
    660     )
    662 elif isinstance(data, dict):
    663     # GH#38939 de facto copy defaults to False only in non-dict cases
--> 664     mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
    665 elif isinstance(data, ma.MaskedArray):
    666     import numpy.ma.mrecords as mrecords

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\internals\construction.py:493, in dict_to_mgr(data, index, columns, dtype, typ, copy)
    489     else:
    490         # dtype check to exclude e.g. range objects, scalars
    491         arrays = [x.copy() if hasattr(x, "dtype") else x for x in arrays]
--> 493 return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\internals\construction.py:118, in arrays_to_mgr(arrays, columns, index, dtype, verify_integrity, typ, consolidate)
    115 if verify_integrity:
    116     # figure out the index, if necessary
    117     if index is None:
--> 118         index = _extract_index(arrays)
    119     else:
    120         index = ensure_index(index)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\internals\construction.py:666, in _extract_index(data)
    664 lengths = list(set(raw_lengths))
    665 if len(lengths) > 1:
--> 666     raise ValueError("All arrays must be of the same length")
    668 if have_dicts:
    669     raise ValueError(
    670         "Mixing dicts with non-Series may lead to ambiguous ordering."
    671     )

ValueError: All arrays must be of the same length

DataFrame from Dict of Series

Example

df
import pandas as pd
​
data = {'Male':pd.Series([32,52,44],index=['A','B','C']),'Female':pd.Series([23,25,3],index=['A','B','C'])}
​
df = pd.DataFrame(data)
​
print(df)
   Male  Female
A    32      23
B    52      25
C    44       3
Row Operations

Selection Using Label

import pandas as pd
​
data = {'Male':pd.Series([32,52,44],index = ['PHYSICS','MATHS','CHEMISTRY']),'Female':pd.Series([23,25,32],index=['PHYSICS','MATHS','CHEMISTRY'])}
​
df = pd.DataFrame(data)
​
print(df)
​
print()
​
print(df.loc['CHEMISTRY'])
           Male  Female
PHYSICS      32      23
MATHS        52      25
CHEMISTRY    44      32

Male      44
Female    32
Name: CHEMISTRY, dtype: int64
Selection Using Integer

import pandas as pd
​
data = {'Male':pd.Series([32,52,44],index=['A','B','C']),'Female':pd.Series([23,25,32],index=['A','B','C'])}
​
df = pd.DataFrame(data)
​
print(df)
​
print()
​
print(df.iloc[1])
   Male  Female
A    32      23
B    52      25
C    44      32

Male      52
Female    25
Name: B, dtype: int64
Row Slicing

d
import pandas as pd
​
list1 = ['Aakash','Sarvesh','Smith','Swaraj']
​
list2 = [30,25,20,33]
​
data = {'Name':list1,'Score':list2}
​
df = pd.DataFrame(data)
​
print(df)
​
print()
​
print(df.iloc[1:3])
      Name  Score
0   Aakash     30
1  Sarvesh     25
2    Smith     20
3   Swaraj     33

      Name  Score
1  Sarvesh     25
2    Smith     20
Column Operations

Selection Using Label

import pandas as pd
​
# Generating data
data = {'Male' : pd.Series([32, 52, 44], index=['A', 'B', 'C']),
   'Female' : pd.Series([23, 25, 32], index=['A', 'B', 'C'])}
​
df = pd.DataFrame(data)
print(df)
print()
​
print(df['Male'])
   Male  Female
A    32      23
B    52      25
C    44      32

A    32
B    52
C    44
Name: Male, dtype: int64
Selection Using Integer

:, 0:1
import pandas as pd
​
# Generating data
data = {'Male' : pd.Series([32, 52, 44], index=['A', 'B', 'C']),
   'Female' : pd.Series([23, 25, 32], index=['A', 'B', 'C'])}
​
df = pd.DataFrame(data)
print(df)
print()
​
print(df.iloc[:, 0:1])
   Male  Female
A    32      23
B    52      25
C    44      32

   Male
A    32
B    52
C    44


Selecting, Extracting and Slicing Dataframes Pandas

import pandas as pd
​
df = pd.read_csv(r'C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\test.csv')
​
df.head()
PassengerId	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked
0	892	3	Kelly, Mr. James	male	34.5	0	0	330911	7.8292	NaN	Q
1	893	3	Wilkes, Mrs. James (Ellen Needs)	female	47.0	1	0	363272	7.0000	NaN	S
2	894	2	Myles, Mr. Thomas Francis	male	62.0	0	0	240276	9.6875	NaN	Q
3	895	3	Wirz, Mr. Albert	male	27.0	0	0	315154	8.6625	NaN	S
4	896	3	Hirvonen, Mrs. Alexander (Helga E Lindqvist)	female	22.0	1	1	3101298	12.2875	NaN	S
Selecting Dataframes

Column Selection
  Cell In[65], line 1
    Column Selection
           ^
SyntaxError: invalid syntax


Column Selection

i
col_name = df['Name']
​
print(col_name)
0                                  Kelly, Mr. James
1                  Wilkes, Mrs. James (Ellen Needs)
2                         Myles, Mr. Thomas Francis
3                                  Wirz, Mr. Albert
4      Hirvonen, Mrs. Alexander (Helga E Lindqvist)
                           ...                     
413                              Spector, Mr. Woolf
414                    Oliva y Ocana, Dona. Fermina
415                    Saether, Mr. Simon Sivertsen
416                             Ware, Mr. Frederick
417                        Peter, Master. Michael J
Name: Name, Length: 418, dtype: object
Row Selection

i
selected_row = df.iloc[0]
​
print(selected_row)
PassengerId                 892
Pclass                        3
Name           Kelly, Mr. James
Sex                        male
Age                        34.5
SibSp                         0
Parch                         0
Ticket                   330911
Fare                     7.8292
Cabin                       NaN
Embarked                      Q
Name: 0, dtype: object
Boolean Indexing

filtered
filtered = df[df['Name'] == 'Kelly,Mr.James']
​
print(filtered)
Empty DataFrame
Columns: [PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked]
Index: []
filtered = df[df['Age']<10]
​
filtered.head()
PassengerId	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked
21	913	3	Olsen, Master. Artur Karl	male	9.0	0	1	C 17368	3.1708	NaN	S
80	972	3	Boulos, Master. Akar	male	6.0	1	1	2678	15.2458	NaN	C
89	981	2	Wells, Master. Ralph Lester	male	2.0	1	1	29103	23.0000	NaN	S
117	1009	3	Sandstrom, Miss. Beatrice Irene	female	1.0	1	1	PP 9549	16.7000	G6	S
161	1053	3	Touma, Master. Georges Youssef	male	7.0	1	1	2650	15.2458	NaN	C
Extracting Dataframes

Integer-based Extraction

extracted_value = df.iat[0, 2]
​
print(extracted_value)
Kelly, Mr. James
Label-based Extraction

extracted_value = df.at[0,"Fare"]
​
print(extracted_value)
7.8292
Slicing Dataframes

Integer-based Slicing

sliced_df
sliced_df = df.iloc[0:3, 0:2]
​
print(sliced_df)
   PassengerId  Pclass
0          892       3
1          893       3
2          894       2
sliced_df
sliced_df = df.iloc[:, 0:2]
​
print(sliced_df)
     PassengerId  Pclass
0            892       3
1            893       3
2            894       2
3            895       3
4            896       3
..           ...     ...
413         1305       3
414         1306       1
415         1307       3
416         1308       3
417         1309       3

[418 rows x 2 columns]
Label-based Slicing

sliced_df = df.loc[5:10,"Name":"Age"]
​
print(sliced_df)
                                         Name     Sex   Age
5                  Svensson, Mr. Johan Cervin    male  14.0
6                        Connolly, Miss. Kate  female  30.0
7                Caldwell, Mr. Albert Francis    male  26.0
8   Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female  18.0
9                     Davies, Mr. John Samuel    male  21.0
10                           Ilieff, Mr. Ylio    male   NaN


Data Cleaning

import numpy as np
​
import pandas as pd
​
import seaborn as sns
​
import matplotlib.pyplot as plt
​
placement_df = pd.read_csv(r'C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\Placement_Data_Full_Class.csv')
​
print(placement_df.head(5))
   Sno Gender  10th % SSC Board  12th % HSC Board 12th Stream  Degree %  \
0    1      M   67.00    Others   91.00    Others    Commerce     58.00   
1    2      M   79.33   Central   78.33    Others     Science     77.48   
2    3      M   65.00   Central   68.00   Central        Arts     64.00   
3    4      M   56.00   Central   52.00   Central     Science     52.00   
4    5      M   85.80   Central   73.60   Central    Commerce     73.30   

  Degree stream Work exp specialisation  Mba %      status    salary  
0      Sci&Tech       No         Mkt&HR  58.80      Placed  270000.0  
1      Sci&Tech      Yes        Mkt&Fin  66.28      Placed  200000.0  
2     Comm&Mgmt       No        Mkt&Fin  57.80      Placed  250000.0  
3      Sci&Tech       No         Mkt&HR  59.43  Not Placed       NaN  
4     Comm&Mgmt       No        Mkt&Fin  55.50      Placed  425000.0  
print(placement_df.info())
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 215 entries, 0 to 214
Data columns (total 14 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   Sno             215 non-null    int64  
 1   Gender          215 non-null    object 
 2   10th %          215 non-null    float64
 3   SSC Board       215 non-null    object 
 4   12th %          215 non-null    float64
 5   HSC Board       215 non-null    object 
 6   12th Stream     215 non-null    object 
 7   Degree %        215 non-null    float64
 8   Degree stream   215 non-null    object 
 9   Work exp        215 non-null    object 
 10  specialisation  215 non-null    object 
 11  Mba %           215 non-null    float64
 12  status          215 non-null    object 
 13  salary          148 non-null    float64
dtypes: float64(5), int64(1), object(8)
memory usage: 23.6+ KB
None
print(sns.boxplot(x=placement_df.salary))
Axes(0.125,0.11;0.775x0.77)

x=placement_df.salary,kde=True
print(sns.displot(x=placement_df.salary,kde=True))
<seaborn.axisgrid.FacetGrid object at 0x000001D78E413BD0>

Dropping Columns or Rows with missing values

df_after_dropping_nan_column=placement_df.dropna(axis=1)
​
print(df_after_dropping_nan_column.head(5))
   Sno Gender  10th % SSC Board  12th % HSC Board 12th Stream  Degree %  \
0    1      M   67.00    Others   91.00    Others    Commerce     58.00   
1    2      M   79.33   Central   78.33    Others     Science     77.48   
2    3      M   65.00   Central   68.00   Central        Arts     64.00   
3    4      M   56.00   Central   52.00   Central     Science     52.00   
4    5      M   85.80   Central   73.60   Central    Commerce     73.30   

  Degree stream Work exp specialisation  Mba %      status  
0      Sci&Tech       No         Mkt&HR  58.80      Placed  
1      Sci&Tech      Yes        Mkt&Fin  66.28      Placed  
2     Comm&Mgmt       No        Mkt&Fin  57.80      Placed  
3      Sci&Tech       No         Mkt&HR  59.43  Not Placed  
4     Comm&Mgmt       No        Mkt&Fin  55.50      Placed  
df_after_dropping_nan_rows=placement_df.dropna()
​
print(df_after_dropping_nan_rows.head(5))
   Sno Gender  10th % SSC Board  12th % HSC Board 12th Stream  Degree %  \
0    1      M   67.00    Others   91.00    Others    Commerce     58.00   
1    2      M   79.33   Central   78.33    Others     Science     77.48   
2    3      M   65.00   Central   68.00   Central        Arts     64.00   
4    5      M   85.80   Central   73.60   Central    Commerce     73.30   
7    8      M   82.00   Central   64.00   Central     Science     66.00   

  Degree stream Work exp specialisation  Mba %  status    salary  
0      Sci&Tech       No         Mkt&HR  58.80  Placed  270000.0  
1      Sci&Tech      Yes        Mkt&Fin  66.28  Placed  200000.0  
2     Comm&Mgmt       No        Mkt&Fin  57.80  Placed  250000.0  
4     Comm&Mgmt       No        Mkt&Fin  55.50  Placed  425000.0  
7      Sci&Tech      Yes        Mkt&Fin  62.14  Placed  252000.0  
Filling missing values with mean

#filling null values with mean
​
placement_df_mean=placement_df.copy()
​
placement_df_mean["salary"]=placement_df["salary"].fillna(placement_df["salary"].mean())
​
print(placement_df_mean.head(5))
   Sno Gender  10th % SSC Board  12th % HSC Board 12th Stream  Degree %  \
0    1      M   67.00    Others   91.00    Others    Commerce     58.00   
1    2      M   79.33   Central   78.33    Others     Science     77.48   
2    3      M   65.00   Central   68.00   Central        Arts     64.00   
3    4      M   56.00   Central   52.00   Central     Science     52.00   
4    5      M   85.80   Central   73.60   Central    Commerce     73.30   

  Degree stream Work exp specialisation  Mba %      status         salary  
0      Sci&Tech       No         Mkt&HR  58.80      Placed  270000.000000  
1      Sci&Tech      Yes        Mkt&Fin  66.28      Placed  200000.000000  
2     Comm&Mgmt       No        Mkt&Fin  57.80      Placed  250000.000000  
3      Sci&Tech       No         Mkt&HR  59.43  Not Placed  288655.405405  
4     Comm&Mgmt       No        Mkt&Fin  55.50      Placed  425000.000000  
#filling null values with median
​
placement_df_median=placement_df.copy()
​
placement_df_median["salary"]=placement_df["salary"].fillna(placement_df["salary"].median())
​
print(placement_df_median.head(5))
   Sno Gender  10th % SSC Board  12th % HSC Board 12th Stream  Degree %  \
0    1      M   67.00    Others   91.00    Others    Commerce     58.00   
1    2      M   79.33   Central   78.33    Others     Science     77.48   
2    3      M   65.00   Central   68.00   Central        Arts     64.00   
3    4      M   56.00   Central   52.00   Central     Science     52.00   
4    5      M   85.80   Central   73.60   Central    Commerce     73.30   

  Degree stream Work exp specialisation  Mba %      status    salary  
0      Sci&Tech       No         Mkt&HR  58.80      Placed  270000.0  
1      Sci&Tech      Yes        Mkt&Fin  66.28      Placed  200000.0  
2     Comm&Mgmt       No        Mkt&Fin  57.80      Placed  250000.0  
3      Sci&Tech       No         Mkt&HR  59.43  Not Placed  265000.0  
4     Comm&Mgmt       No        Mkt&Fin  55.50      Placed  425000.0  
Filling missing values using the mode

#filling null values with mode
​
placement_df_mode=placement_df.copy()
​
placement_df_mode["salary"]=placement_df["salary"].fillna(placement_df["salary"].mode()[0])
​
print(placement_df_mode.head(5))
   Sno Gender  10th % SSC Board  12th % HSC Board 12th Stream  Degree %  \
0    1      M   67.00    Others   91.00    Others    Commerce     58.00   
1    2      M   79.33   Central   78.33    Others     Science     77.48   
2    3      M   65.00   Central   68.00   Central        Arts     64.00   
3    4      M   56.00   Central   52.00   Central     Science     52.00   
4    5      M   85.80   Central   73.60   Central    Commerce     73.30   

  Degree stream Work exp specialisation  Mba %      status    salary  
0      Sci&Tech       No         Mkt&HR  58.80      Placed  270000.0  
1      Sci&Tech      Yes        Mkt&Fin  66.28      Placed  200000.0  
2     Comm&Mgmt       No        Mkt&Fin  57.80      Placed  250000.0  
3      Sci&Tech       No         Mkt&HR  59.43  Not Placed  300000.0  
4     Comm&Mgmt       No        Mkt&Fin  55.50      Placed  425000.0  
Filling the missing values with values that come before or after them

placement_df_bfill=placement_df.copy()
​
placement_df_bfill["salary"]=placement_df["salary"].fillna(method='bfill',axis=0).fillna(0)
​
placement_df_bfill.head(5)
Sno	Gender	10th %	SSC Board	12th %	HSC Board	12th Stream	Degree %	Degree stream	Work exp	specialisation	Mba %	status	salary
0	1	M	67.00	Others	91.00	Others	Commerce	58.00	Sci&Tech	No	Mkt&HR	58.80	Placed	270000.0
1	2	M	79.33	Central	78.33	Others	Science	77.48	Sci&Tech	Yes	Mkt&Fin	66.28	Placed	200000.0
2	3	M	65.00	Central	68.00	Central	Arts	64.00	Comm&Mgmt	No	Mkt&Fin	57.80	Placed	250000.0
3	4	M	56.00	Central	52.00	Central	Science	52.00	Sci&Tech	No	Mkt&HR	59.43	Not Placed	425000.0
4	5	M	85.80	Central	73.60	Central	Commerce	73.30	Comm&Mgmt	No	Mkt&Fin	55.50	Placed	425000.0
5
placement_df_ffill=placement_df.copy()
​
placement_df_ffill["salary"]=placement_df["salary"].fillna(method='ffill',axis=0).fillna(0)
​
placement_df_ffill.head(5)
Sno	Gender	10th %	SSC Board	12th %	HSC Board	12th Stream	Degree %	Degree stream	Work exp	specialisation	Mba %	status	salary
0	1	M	67.00	Others	91.00	Others	Commerce	58.00	Sci&Tech	No	Mkt&HR	58.80	Placed	270000.0
1	2	M	79.33	Central	78.33	Others	Science	77.48	Sci&Tech	Yes	Mkt&Fin	66.28	Placed	200000.0
2	3	M	65.00	Central	68.00	Central	Arts	64.00	Comm&Mgmt	No	Mkt&Fin	57.80	Placed	250000.0
3	4	M	56.00	Central	52.00	Central	Science	52.00	Sci&Tech	No	Mkt&HR	59.43	Not Placed	250000.0
4	5	M	85.80	Central	73.60	Central	Commerce	73.30	Comm&Mgmt	No	Mkt&Fin	55.50	Placed	425000.0
Removing duplicate rows

#show all the duplicate values as True except for the first
​
print(placement_df.duplicated(subset=None,keep='first'))
0      False
1      False
2      False
3      False
4      False
       ...  
210    False
211    False
212    False
213    False
214    False
Length: 215, dtype: bool
5
#dropping second-row assuming that it is the duplicate of the first row 
​
placement_df_drop_row=placement_df.drop(placement_df.index[[1]])
​
placement_df_drop_row.head(5)
Sno	Gender	10th %	SSC Board	12th %	HSC Board	12th Stream	Degree %	Degree stream	Work exp	specialisation	Mba %	status	salary
0	1	M	67.0	Others	91.0	Others	Commerce	58.00	Sci&Tech	No	Mkt&HR	58.80	Placed	270000.0
2	3	M	65.0	Central	68.0	Central	Arts	64.00	Comm&Mgmt	No	Mkt&Fin	57.80	Placed	250000.0
3	4	M	56.0	Central	52.0	Central	Science	52.00	Sci&Tech	No	Mkt&HR	59.43	Not Placed	NaN
4	5	M	85.8	Central	73.6	Central	Commerce	73.30	Comm&Mgmt	No	Mkt&Fin	55.50	Placed	425000.0
5	6	M	55.0	Others	49.8	Others	Science	67.25	Sci&Tech	Yes	Mkt&Fin	51.58	Not Placed	NaN


----------------------------------date:04/07/2024-------------------------------------------------

Getting relevant or usable form of data from columns

import zipfile
​
movie_df = pd.read_csv(r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\tmdb_5000_movies.csv.zip\tmdb_5000_movies.csv")
​
movie_df.head(3)
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[3], line 3
      1 import zipfile
----> 3 movie_df = pd.read_csv(r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\tmdb_5000_movies.csv.zip\tmdb_5000_movies.csv")
      5 movie_df.head(3)

NameError: name 'pd' is not defined

import pandas as pd
import zipfile
import pandas as pd
import os
​
# Path to the zip file
zip_file_path = r'C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\tmdb_5000_movies.csv.zip'
# Extract directory
extract_dir = r'C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\tmdb_5000_movies'
​
# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)
​
# Path to the extracted CSV file
csv_file_path = os.path.join(extract_dir, 'tmdb_5000_movies.csv')
​
# Read the CSV file
movie_df = pd.read_csv(csv_file_path)
​
# Display the first 3 rows
movie_df.head(3)
​
budget	genres	homepage	id	keywords	original_language	original_title	overview	popularity	production_companies	production_countries	release_date	revenue	runtime	spoken_languages	status	tagline	title	vote_average	vote_count
0	237000000	[{"id": 28, "name": "Action"}, {"id": 12, "nam...	http://www.avatarmovie.com/	19995	[{"id": 1463, "name": "culture clash"}, {"id":...	en	Avatar	In the 22nd century, a paraplegic Marine is di...	150.437577	[{"name": "Ingenious Film Partners", "id": 289...	[{"iso_3166_1": "US", "name": "United States o...	2009-12-10	2787965087	162.0	[{"iso_639_1": "en", "name": "English"}, {"iso...	Released	Enter the World of Pandora.	Avatar	7.2	11800
1	300000000	[{"id": 12, "name": "Adventure"}, {"id": 14, "...	http://disney.go.com/disneypictures/pirates/	285	[{"id": 270, "name": "ocean"}, {"id": 726, "na...	en	Pirates of the Caribbean: At World's End	Captain Barbossa, long believed to be dead, ha...	139.082615	[{"name": "Walt Disney Pictures", "id": 2}, {"...	[{"iso_3166_1": "US", "name": "United States o...	2007-05-19	961000000	169.0	[{"iso_639_1": "en", "name": "English"}]	Released	At the end of the world, the adventure begins.	Pirates of the Caribbean: At World's End	6.9	4500
2	245000000	[{"id": 28, "name": "Action"}, {"id": 12, "nam...	http://www.sonypictures.com/movies/spectre/	206647	[{"id": 470, "name": "spy"}, {"id": 818, "name...	en	Spectre	A cryptic message from Bond’s past sends him o...	107.376788	[{"name": "Columbia Pictures", "id": 5}, {"nam...	[{"iso_3166_1": "GB", "name": "United Kingdom"...	2015-10-26	880674609	148.0	[{"iso_639_1": "fr", "name": "Fran\u00e7ais"},...	Released	A Plan No One Escapes	Spectre	6.3	4466
Parsing dates

movie_df_copy=movie_df.dropna()
​
print(movie_df_copy["release_date"].dtypes)
object
##making a new column with datetime64[ns] type
​
movie_df_copy['parsed_release_date']=movie_df_copy['release_date'].astype('datetime64[ns]')
​
print("Datatype pf parsed_released_date column")
​
print(movie_df_copy['parsed_release_date'].dtypes)
​
print("Day")
​
print(movie_df_copy['parsed_release_date'].dt.day.head(5))
​
print("Month:")
​
print(movie_df_copy['parsed_release_date'].dt.month.head(5))
​
print("Year:")
​
print(movie_df_copy['parsed_release_date'].dt.year.head(5))
Datatype pf parsed_released_date column
datetime64[ns]
Day
0    10
1    19
2    26
3    16
4     7
Name: parsed_release_date, dtype: int64
Month:
0    12
1     5
2    10
3     7
4     3
Name: parsed_release_date, dtype: int64
Year:
0    2009
1    2007
2    2015
3    2012
4    2012
Name: parsed_release_date, dtype: int64
C:\Users\Sourav Mukherjee\AppData\Local\Temp\ipykernel_32188\1636154300.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  movie_df_copy['parsed_release_date']=movie_df_copy['release_date'].astype('datetime64[ns]')
Converting string to object

5
import json
​
print(movie_df["genres"][0])
​
print(type(movie_df["genres"][0]))
​
genre_arr=[]
​
for json_obj_arr_str in movie_df["genres"]:
    genre_obj_arr=json.loads(json_obj_arr_str)
    for j in range(len(genre_obj_arr)):
        genre_arr.append(genre_obj_arr[j]["name"])
        
genre_df = pd.DataFrame(genre_arr, columns = ['genres']) 
​
genre_df.head(5)
[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]
<class 'str'>
genres
0	Action
1	Adventure
2	Fantasy
3	Science Fiction
4	Adventure
Filtering outliers

import seaborn as sns
import seaborn as sns
​
sns.displot(x=movie_df["runtime"])
<seaborn.axisgrid.FacetGrid at 0x20214a9cc50>

3
movie_df[movie_df['runtime']<50].head(3)
budget	genres	homepage	id	keywords	original_language	original_title	overview	popularity	production_companies	production_countries	release_date	revenue	runtime	spoken_languages	status	tagline	title	vote_average	vote_count
1011	0	[{"id": 27, "name": "Horror"}]	NaN	53953	[{"id": 10292, "name": "gore"}, {"id": 12339, ...	de	The Tooth Fairy	A woman and her daughter (Nicole Muñoz) encoun...	0.716764	[]	[]	2006-08-08	0	0.0	[{"iso_639_1": "en", "name": "English"}, {"iso...	Released	NaN	The Tooth Fairy	4.3	13
3112	0	[{"id": 18, "name": "Drama"}, {"id": 80, "name...	NaN	41894	[]	en	Blood Done Sign My Name	A drama based on the true story in which a bla...	0.397341	[]	[]	2010-02-01	0	0.0	[]	Released	No one changes the world alone.	Blood Done Sign My Name	6.0	5
3354	0	[{"id": 99, "name": "Documentary"}]	NaN	24977	[{"id": 6075, "name": "sport"}]	en	Michael Jordan to the Max	This documentary showcases basketball player M...	1.830306	[{"name": "IMAX", "id": 3447}]	[{"iso_3166_1": "US", "name": "United States o...	2000-05-05	21268532	46.0	[{"iso_639_1": "en", "name": "English"}]	Released	Up close some heroes get even bigger.	Michael Jordan to the Max	7.5	10
#We need to remove all the movies with runtime 0 minutes.
movie_df_filtered = movie_df[movie_df["runtime"]>0]
​
print(movie_df_filtered[movie_df_filtered["runtime"]==0])
Empty DataFrame
Columns: [budget, genres, homepage, id, keywords, original_language, original_title, overview, popularity, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, vote_average, vote_count]
Index: []
Removing inconsistency in data

import pandas as pd

# Correct path to the extracted CSV file
file_path = r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\zomato_restaurants_in_India_inconsistent.csv"

# Reading the CSV file
zomato_df = pd.read_csv(file_path)

# Displaying the first three rows of the DataFrame
print(zomato_df.head(3))
import pandas as pd
​
# Correct path to the extracted CSV file
file_path = r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\zomato_restaurants_in_India_inconsistent.csv"
​
# Reading the CSV file
zomato_df = pd.read_csv(file_path)
​
# Displaying the first three rows of the DataFrame
print(zomato_df.head(3))
​
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
Cell In[23], line 7
      4 file_path = r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\zomato_restaurants_in_India_inconsistent.csv"
      6 # Reading the CSV file
----> 7 zomato_df = pd.read_csv(file_path)
      9 # Displaying the first three rows of the DataFrame
     10 print(zomato_df.head(3))

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\util\_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)
    209     else:
    210         kwargs[new_arg_name] = new_arg_value
--> 211 return func(*args, **kwargs)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\util\_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)
    325 if len(args) > num_allow_args:
    326     warnings.warn(
    327         msg.format(arguments=_format_argument_list(allow_args)),
    328         FutureWarning,
    329         stacklevel=find_stack_level(),
    330     )
--> 331 return func(*args, **kwargs)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\io\parsers\readers.py:950, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)
    935 kwds_defaults = _refine_defaults_read(
    936     dialect,
    937     delimiter,
   (...)
    946     defaults={"delimiter": ","},
    947 )
    948 kwds.update(kwds_defaults)
--> 950 return _read(filepath_or_buffer, kwds)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\io\parsers\readers.py:605, in _read(filepath_or_buffer, kwds)
    602 _validate_names(kwds.get("names", None))
    604 # Create the parser.
--> 605 parser = TextFileReader(filepath_or_buffer, **kwds)
    607 if chunksize or iterator:
    608     return parser

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\io\parsers\readers.py:1442, in TextFileReader.__init__(self, f, engine, **kwds)
   1439     self.options["has_index_names"] = kwds["has_index_names"]
   1441 self.handles: IOHandles | None = None
-> 1442 self._engine = self._make_engine(f, self.engine)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\io\parsers\readers.py:1735, in TextFileReader._make_engine(self, f, engine)
   1733     if "b" not in mode:
   1734         mode += "b"
-> 1735 self.handles = get_handle(
   1736     f,
   1737     mode,
   1738     encoding=self.options.get("encoding", None),
   1739     compression=self.options.get("compression", None),
   1740     memory_map=self.options.get("memory_map", False),
   1741     is_text=is_text,
   1742     errors=self.options.get("encoding_errors", "strict"),
   1743     storage_options=self.options.get("storage_options", None),
   1744 )
   1745 assert self.handles is not None
   1746 f = self.handles.handle

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\io\common.py:856, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)
    851 elif isinstance(handle, str):
    852     # Check whether the filename is to be opened in binary mode.
    853     # Binary mode does not support 'encoding' and 'newline'.
    854     if ioargs.encoding and "b" not in ioargs.mode:
    855         # Encoding
--> 856         handle = open(
    857             handle,
    858             ioargs.mode,
    859             encoding=ioargs.encoding,
    860             errors=errors,
    861             newline="",
    862         )
    863     else:
    864         # Binary mode
    865         handle = open(handle, ioargs.mode)

FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\Sourav Mukherjee\\Dropbox\\PC\\Downloads\\zomato_restaurants_in_India_inconsistent.csv'

import zipfile
import os
​
# Path to the ZIP file
zip_file_path = r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\zomato_restaurants_in_India_inconsistent.csv.zip"
​
# Path to extract the files
extract_path = r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads"
​
# Extracting the ZIP file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)
​
import pandas as pd
​
# Path to the extracted CSV file
file_path = r"C:\Users\Sourav Mukherjee\Dropbox\PC\Downloads\zomato_restaurants_in_India_inconsistent.csv"
​
# Check if the file exists
if os.path.exists(file_path):
    print("File exists. Proceeding to read the CSV file.")
    # Reading the CSV file
    zomato_df = pd.read_csv(file_path)
    # Displaying the first three rows of the DataFrame
    print(zomato_df.head(3))
else:
    print("File does not exist. Please check the file path.")
​
File exists. Proceeding to read the CSV file.
    res_id                            name    establishment  \
0  3400299                     Bikanervala  ['Quick Bites']   
1  3400005  Mama Chicken Mama Franky House  ['Quick Bites']   
2  3401013                   Bhagat Halwai  ['Quick Bites']   

                                                 url  \
0  https://www.zomato.com/agra/bikanervala-khanda...   
1  https://www.zomato.com/agra/mama-chicken-mama-...   
2  https://www.zomato.com/agra/bhagat-halwai-2-sh...   

                                             address  city  city_id  \
0  Kalyani Point, Near Tulsi Cinema, Bypass Road,...  Agra       34   
1        Main Market, Sadar Bazaar, Agra Cantt, Agra  Agra       34   
2  62/1, Near Easy Day, West Shivaji Nagar, Goalp...  Agra       34   

     locality   latitude  longitude  ... price_range  currency  \
0    Khandari  27.211450  78.002381  ...           2       Rs.   
1  Agra Cantt  27.160569  78.011583  ...           2       Rs.   
2    Shahganj  27.182938  77.979684  ...           1       Rs.   

                                          highlights aggregate_rating  \
0  ['Lunch', 'Takeaway Available', 'Credit Card',...              4.4   
1  ['Delivery', 'No Alcohol Available', 'Dinner',...              4.4   
2  ['No Alcohol Available', 'Dinner', 'Takeaway A...              4.2   

  rating_text  votes  photo_count opentable_support delivery  takeaway  
0   Very Good    814          154               0.0       -1        -1  
1   Very Good   1203          161               0.0       -1        -1  
2   Very Good    801          107               0.0        1        -1  

[3 rows x 26 columns]
3
zomato_df.head(3)
res_id	name	establishment	url	address	city	city_id	locality	latitude	longitude	...	price_range	currency	highlights	aggregate_rating	rating_text	votes	photo_count	opentable_support	delivery	takeaway
0	3400299	Bikanervala	['Quick Bites']	https://www.zomato.com/agra/bikanervala-khanda...	Kalyani Point, Near Tulsi Cinema, Bypass Road,...	Agra	34	Khandari	27.211450	78.002381	...	2	Rs.	['Lunch', 'Takeaway Available', 'Credit Card',...	4.4	Very Good	814	154	0.0	-1	-1
1	3400005	Mama Chicken Mama Franky House	['Quick Bites']	https://www.zomato.com/agra/mama-chicken-mama-...	Main Market, Sadar Bazaar, Agra Cantt, Agra	Agra	34	Agra Cantt	27.160569	78.011583	...	2	Rs.	['Delivery', 'No Alcohol Available', 'Dinner',...	4.4	Very Good	1203	161	0.0	-1	-1
2	3401013	Bhagat Halwai	['Quick Bites']	https://www.zomato.com/agra/bhagat-halwai-2-sh...	62/1, Near Easy Day, West Shivaji Nagar, Goalp...	Agra	34	Shahganj	27.182938	77.979684	...	1	Rs.	['No Alcohol Available', 'Dinner', 'Takeaway A...	4.2	Very Good	801	107	0.0	1	-1
3 rows × 26 columns

#printing the unique values of city column
​
zomato_df["city"].unique()
array(['Agra', 'agra', 'Ahmedabad', 'Gandhinagar', 'Ajmer', 'Alappuzha',
       'Allahabad', 'Amravati', 'Amritsar', 'Aurangabad', 'Bangalore',
       'Bhopal', 'Bhubaneshwar', 'Chandigarh', 'Mohali', 'Panchkula',
       'Zirakpur', 'Nayagaon', 'Chennai', 'Coimbatore', 'Cuttack',
       'Darjeeling', 'Dehradun', 'New Delhi', 'Gurgaon', 'Noida',
       'Faridabad', 'Ghaziabad', 'Greater Noida', 'Dharamshala',
       'Gangtok', 'Goa', 'Gorakhpur', 'Guntur', 'Guwahati', 'Gwalior',
       'Haridwar', 'Hyderabad', 'Secunderabad', 'hyderabad',
       '    Hyderabad', 'Indore', 'Jabalpur', 'Jaipur', 'Jalandhar',
       'Jammu', 'Jamnagar', 'Jamshedpur', 'Jhansi', 'Jodhpur', 'Junagadh',
       'Kanpur', 'Kharagpur', 'Kochi', 'Kolhapur', 'Kolkata', 'Howrah',
       'Kota', 'Lucknow', 'Ludhiana', 'Madurai', 'Manali', 'Mangalore',
       'Manipal', 'Udupi', 'Meerut', 'Mumbai', 'Thane', 'Navi Mumbai',
       '       mumbai', 'Mussoorie', 'Mysore', 'Nagpur', 'Nainital',
       'Nasik', 'Nashik', 'Neemrana', 'Ooty', 'Palakkad', 'Patiala',
       'Patna', 'patna            ', 'Puducherry', 'Pune', '       pune',
       'Pushkar', 'Raipur', 'Rajkot', 'Ranchi', 'Rishikesh', 'Salem',
       'Shimla', 'Siliguri', 'Srinagar', 'Surat', 'Thrissur', 'Tirupati',
       'Trichy', 'Trivandrum', 'Udaipur', 'Varanasi', 'Vellore',
       'Vijayawada', 'Vizag', 'Vadodara'], dtype=object)
Removing white spaces

i
zomato_df_letter = zomato_df.copy()
​
zomato_df_letter["city"] = zomato_df_letter["city"].str.strip()
​
unique_cities = zomato_df_letter["city"].unique()
​
print(unique_cities)
['Agra' 'agra' 'Ahmedabad' 'Gandhinagar' 'Ajmer' 'Alappuzha' 'Allahabad'
 'Amravati' 'Amritsar' 'Aurangabad' 'Bangalore' 'Bhopal' 'Bhubaneshwar'
 'Chandigarh' 'Mohali' 'Panchkula' 'Zirakpur' 'Nayagaon' 'Chennai'
 'Coimbatore' 'Cuttack' 'Darjeeling' 'Dehradun' 'New Delhi' 'Gurgaon'
 'Noida' 'Faridabad' 'Ghaziabad' 'Greater Noida' 'Dharamshala' 'Gangtok'
 'Goa' 'Gorakhpur' 'Guntur' 'Guwahati' 'Gwalior' 'Haridwar' 'Hyderabad'
 'Secunderabad' 'hyderabad' 'Indore' 'Jabalpur' 'Jaipur' 'Jalandhar'
 'Jammu' 'Jamnagar' 'Jamshedpur' 'Jhansi' 'Jodhpur' 'Junagadh' 'Kanpur'
 'Kharagpur' 'Kochi' 'Kolhapur' 'Kolkata' 'Howrah' 'Kota' 'Lucknow'
 'Ludhiana' 'Madurai' 'Manali' 'Mangalore' 'Manipal' 'Udupi' 'Meerut'
 'Mumbai' 'Thane' 'Navi Mumbai' 'mumbai' 'Mussoorie' 'Mysore' 'Nagpur'
 'Nainital' 'Nasik' 'Nashik' 'Neemrana' 'Ooty' 'Palakkad' 'Patiala'
 'Patna' 'patna' 'Puducherry' 'Pune' 'pune' 'Pushkar' 'Raipur' 'Rajkot'
 'Ranchi' 'Rishikesh' 'Salem' 'Shimla' 'Siliguri' 'Srinagar' 'Surat'
 'Thrissur' 'Tirupati' 'Trichy' 'Trivandrum' 'Udaipur' 'Varanasi'
 'Vellore' 'Vijayawada' 'Vizag' 'Vadodara']
Removing capitalization inconsistencies

unique_cities
zomato_df_letter['city'] = zomato_df_letter['city'].str.lower()
​
zomato_df_letter['city'] = zomato_df_letter['city'].str.capitalize()
​
unique_cities = zomato_df_letter["city"].unique()
​
print(unique_cities)
['Agra' 'Ahmedabad' 'Gandhinagar' 'Ajmer' 'Alappuzha' 'Allahabad'
 'Amravati' 'Amritsar' 'Aurangabad' 'Bangalore' 'Bhopal' 'Bhubaneshwar'
 'Chandigarh' 'Mohali' 'Panchkula' 'Zirakpur' 'Nayagaon' 'Chennai'
 'Coimbatore' 'Cuttack' 'Darjeeling' 'Dehradun' 'New delhi' 'Gurgaon'
 'Noida' 'Faridabad' 'Ghaziabad' 'Greater noida' 'Dharamshala' 'Gangtok'
 'Goa' 'Gorakhpur' 'Guntur' 'Guwahati' 'Gwalior' 'Haridwar' 'Hyderabad'
 'Secunderabad' 'Indore' 'Jabalpur' 'Jaipur' 'Jalandhar' 'Jammu'
 'Jamnagar' 'Jamshedpur' 'Jhansi' 'Jodhpur' 'Junagadh' 'Kanpur'
 'Kharagpur' 'Kochi' 'Kolhapur' 'Kolkata' 'Howrah' 'Kota' 'Lucknow'
 'Ludhiana' 'Madurai' 'Manali' 'Mangalore' 'Manipal' 'Udupi' 'Meerut'
 'Mumbai' 'Thane' 'Navi mumbai' 'Mussoorie' 'Mysore' 'Nagpur' 'Nainital'
 'Nasik' 'Nashik' 'Neemrana' 'Ooty' 'Palakkad' 'Patiala' 'Patna'
 'Puducherry' 'Pune' 'Pushkar' 'Raipur' 'Rajkot' 'Ranchi' 'Rishikesh'
 'Salem' 'Shimla' 'Siliguri' 'Srinagar' 'Surat' 'Thrissur' 'Tirupati'
 'Trichy' 'Trivandrum' 'Udaipur' 'Varanasi' 'Vellore' 'Vijayawada' 'Vizag'
 'Vadodara']
